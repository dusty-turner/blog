<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Dusty Turner</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Dusty Turner</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License，please give source if you likes to quote or reproduce.</copyright>
    <lastBuildDate>Thu, 27 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Goal: Read 1000 (Children&#39;s) Books in 2018</title>
      <link>/post/analysis-of-my-children-s-reading-list/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/analysis-of-my-children-s-reading-list/</guid>
      <description>IntroductionOver Christmas 2017, my wife, Jill, resolved that our family (to include babysitters) would read our children over 1000 new books in 2018. More specifically, 29 December 2017 - 28 December 2018.
A goal like this takes dedication, love, and of course, a Data Science-y approach.
Special thanks to Ally, Zia, and Bookbuddy for help in accomplishing this goal!
Also, special thanks to drob and juliasilge who privde the tidytext package and the entire R open-source community I rely on to do this analysis.</description>
    </item>
    
    <item>
      <title>Data Scraping Presentation: Center for Data Analysis and Statistics</title>
      <link>/post/data-scraping-presentation-center-for-data-analysis-and-statistics/</link>
      <pubDate>Tue, 17 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/data-scraping-presentation-center-for-data-analysis-and-statistics/</guid>
      <description>On 17 April 2018, I gave a tutorial to the Department of Mathematical Sciences at West Point and the Sports Analytics Club. The Power Point presentation, R file, and R Markdown file are at my github page at this link</description>
    </item>
    
    <item>
      <title>2017 NCAA College Bowl Pick &#39;em</title>
      <link>/post/2017-ncaa-college-bowl-pick-em/</link>
      <pubDate>Sun, 31 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-ncaa-college-bowl-pick-em/</guid>
      <description>Bowl Season!Its one of the best times of the year. In order to celebrate (and to participate in a little competition), I put together a Shiny App to track my collegues picks over the season. Its improved throughout the season, and there are still improvment’s I’d like to add - but below is a working prototype.
</description>
    </item>
    
    <item>
      <title>2017 MORS Presentation</title>
      <link>/post/2017-mors-presentation/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-mors-presentation/</guid>
      <description>Midway through my first semester teaching at West Point, my mentor, asked me what “scholarship” I was working on. To be honest, at the time, I was doing my best to make sure I understood what material I was teaching the next day and making sure my grading was up-to-date. I had been tinkering around with the idea of ‘data scraping’ which was a nebulous term to be then. I was intrigued by it and had google searched ways to get data in the days before (my old tried and true method of copy and paste was frustratingly slow…).</description>
    </item>
    
    <item>
      <title>Shiny Project: Experimentation with Leaflet, Shapefiles, and Interactivity</title>
      <link>/post/shiny-project/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/shiny-project/</guid>
      <description>Taking A Look Across The Country</description>
    </item>
    
    <item>
      <title>Helping A Colleague Explore Data</title>
      <link>/post/helping-a-colleague-explore-data/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/helping-a-colleague-explore-data/</guid>
      <description>IntroductionA colleague of mine asked me to help him explore a dataset in R. He has little experience in R, so I will provide as much detail as I can in this exploration. My goal here is to make this post both ‘learn-able’ and ‘replicable’.
Install and/or load necessary packagesif (!require(&amp;quot;tidyverse&amp;quot;)) install.packages(&amp;quot;tidyverse&amp;quot;)if (!require(&amp;quot;readr&amp;quot;)) install.packages(&amp;quot;readr&amp;quot;)if (!require(&amp;quot;lubridate&amp;quot;)) install.packages(&amp;quot;lubridate&amp;quot;)if (!require(&amp;quot;stringi&amp;quot;)) install.packages(&amp;quot;stringi&amp;quot;)Set Working Directory If Necessary# setwd(&amp;quot;//filepath/of/your/csvfile&amp;quot;)Read in dataWe use read_csv from the readr package because it does a better job than the base read.</description>
    </item>
    
    <item>
      <title>Mathlete Fantasy Football Analysis</title>
      <link>/post/mathlete-fantasy-football-analysis/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/mathlete-fantasy-football-analysis/</guid>
      <description>IntroductionLets see who really has fantasy football bragging rights and who is just lucky (or unlucky).
During this analysis I will display most of my code. While this doesn’t provided the most pleasent visual experience, it will hopefully help the reader learn from my examples. (And potentially provide feedback on how to improve my methods.)
LibrariesThe libraries I will use for this analysis are the following:</description>
    </item>
    
    <item>
      <title>Blog Introduction</title>
      <link>/post/blog-introduction/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/blog-introduction/</guid>
      <description>As my experience with statistics, computer science, and the all encompasing term, data science, increases, I have decided that it is time to share some of my projects.
Creating this blog serves several purposes.
It archives some projects I’ve created.It makes my work public so I can receive (hopefully) constructive feedback to improve my tools/analysis.
It helps me share what I’ve learned with the community that has been so helpful to me.</description>
    </item>
    
  </channel>
</rss>